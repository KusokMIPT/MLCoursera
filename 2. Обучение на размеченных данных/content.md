## Урок 1
### Обозначения
$x$ - объект
$X$ - пространство объектов
$y=y(x)$ - ответ на объекте x
 $Y$ - пространство ответов
 
  
## Урок 2 (Линейные модели)
$a(x) = <\omega, x>$
Обучение заключается в поиске минимума: $Q(\omega, x) = \dfrac{1}{l} \sum\limits_{i=1}^{l}(<\omega, x_i> - y_i)^2 \rightarrow \min\limits_\omega$ или в матричной форме $Q(\omega, X) = \dfrac{1}{l}\| X \omega -y\|^2\rightarrow \min\limits_\omega$

### Градиентный спуск
есть аналитическое решение, есть с помощью оптимизации градиентным бустингом: $\omega^t = \omega^{t - 1} - \eta_t \nabla Q(\omega^{t - 1}, X)$
Шаг лучше выбирать так, чтобы он уменьшался, например: $\eta_t = \dfrac{k}{t}$

### Стохастический градиентный спуск
$\omega^t = \omega^{t-1} - \eta_t \nabla Q(\omega^{t - 1}, \{x_i\})$, где объект $x_i$ - выбирается случайным образом. 

## Классификация 
$a(x) = sign{\left( \omega_0 + \sum\limits_{j = 1}^{d} \omega_j x^j \right)} = sign <\omega, x>$
**Отступ:** $M_i = y_i <\omega, x_i>$
**Пороговая функция потерь:** $Q(a,x) = \dfrac{1}{l}\sum\limits_{i=1}^l [a(x_i) \neq y_i] = \dfrac{1}{l}\sum\limits_{i = 1}^l [M_i <0]$
Такая функция не гладкая, поэтому мы приблизим её логистической функцией потерь:
$\hat{Q}(a, X) = \dfrac{1}{l}\sum\limits_{i = 1}^l \ln{(\exp{(-y_i<\omega, x_i>})}$


## Урок 3(Переобучение)
1. Регуляризация 
2. Кросс-валидация и отложенная выборка
3. Гиперпараметры


## Урок 4 (Метрики)
### Регрессия
- $MSE(a, X) = $
  
### Классификация 
1. Матрица ошибок
2. Точность и полнота
$precesion(a, X) = \dfrac{TP}{TP + FP}$
$recall(a, X) = \dfrac{TP}{TP + FN}$
3. F - мера 
$F = \dfrac{2 \cdot precision \cdot recall}{precision + recall}$
4. PR - кривая, ROC - кривая 
Строятся они примерно одинаково, рассматриваются различные значения порога и отмечаются точки на графике 
  
## Урок 5 (Линейные модели)
1. Регрессия
- функция ошибка и её аналитичское решение $\mathcal{Q}(\omega, X) = \dfrac{1}{l}\sum\limits_{n=1}^{l}(<\omega, x_i> -  y_i)^2$
2. ОМП
3. Связь регрессии и ОМП
При решение задачи регресии значение отклика приближвается в виде:
$y = a(x) + \varepsilon$, где $a(x)$ - регресионная функция, а компонента $\varepsilon$ описывает шум. 

Находим ОМП:
$a_* = argmin_a \dfrac{1}{l} \sum\limits_{i=1}^{l}(a(x_i) = y_i)^2$
4. Регрессия как оценка среднего(интуиция)
Говорим что $y$ - сл.в с функцией распределения $f(t)$. Тогда средне-квадратичная ошибка : 
$$Q(a(x), X) = \int_t(a - t)^2 f(t) dt$$
$a_* = argmin_a Q(a(x)) = E(y|x)$ (если a - константа, то $a_* = argmin_a Q(a) = E(y)$). 

Ну вот у нас то конечный случай и $Q(a(x), X) = \dfrac{1}{l}\sum\limits_{i=1}^{l}(a(x_i) - y_i)$. Тогда $a_*$ совпадает с дискретным $E(y|x)$

---
А вот если рассматривать среднюю абсолютную ошибку, то:
$a_* = argmin_a Q(a, X)$ - лучшая аппроксимация $med(y|x)$
5. Регуляризация 
L1, L2. Про их различия(L1 - круто использовать для одбора признаков, потому что она зануляет веса)

- Смещение и дисперсия 

6. Логистическая регрессия 
Метод обучения с учителем в задаче бинарной классификации $Y = \{0,1\}$.

Хотим предсказывать не только метку объекта, но и его вероятность попадания в класс, то есть
$P(y=1|x) = \pi(x)$, в качестве $\pi(x) \approx \dfrac{e^{<\omega, x>}}{ 1+ e^{<\omega, x>}}$ (наз. **сигмойдой**), причем мы уже используем  **обобщенную линейную модель**, в которой находим оценку не для условного $E(y|x)$, а для $g(E(y|x))$, где $g :(0,1) \rightarrow \R$)

**log_loss**: $- ln{L(x)} = - \sum\limits_{i=1}^{l}(y_i ln \pi(x_i) + (1 -y_i)ln(1 - \pi(x_i)))$
**Логистическая функция потерь:** $Q(\omega, X) = \sum\limits_{i=1}^{l}\ln{(1 + exp\{-y_i<\omega, x>\})}$

## Урок 6 (Линейный модели_2)  
1. Масштабирование признаков  
- помнить пример почему плохо не масштабировать(антиградиент будет проходить мимо точки минимума)  
- 2 способа масштабирования: 
$x_i^j := \dfrac{x_i^j - \mu_j}{\sigma_j}$
$x_i^j := \dfrac{x_i^j - m_j}{M_j - m_j}$
2. Нелинейные зависимости 
спрямляющее пространство(пространство в котором задача хорошо решается линейной моделью)
- полиноминальные признаки $(x1, ...,x_d) \rightarrow (x_1, ...,x_d, x_1^2,..., x_d^2, x_1x_2, ...,x_{d-1}x_d)$
- логарифмирование
$x_i \rightarrow \ln{(x_i + 1)}$ \ $x_i \rightarrow \ln{(|x_i| + 1)}$ 
3. Категориальные признаки  
x_j - категориальный и принимает значения {c_1, ..., c_n}
- бинарное кодирование : $b_i(x) = [f_j(x) = c_i]$  (заменяем один категориальный на n бинарных).
4. Балансировка данных  
- Undersampling( выбрасивание объектов из большей класса) & Oversampling(дублирование объектов малого класса)
- Стратификация
Добиваемся того, чтобы распределение классов в каждом блоке примерно совпадало с распределением классов в исходной выборке
5. Многоклассовая классификация 
 - ONE-VS-ALL
Решение K задач бинарной классификации9
## Урок 7: Решающие деревья
1. Что это такое. Регрессия и классификация
Условие на внутренних вершинах: $[x^j < t]$ (будем обязательно получать кусочно-постоянную зависимость).
2. Обучение решающих деревьев
Про то, как их лучше строить и убирать склонность к переобучению.
используются **Жадный способ построения**:
- Строим дерево от корня к листья. 
- Способ разбиения каждого потомка $Q(X_m, j, t) \rightarrow \min \limits_{j,t}$ (перебираем параметры так как их конечное число)

В итоге разбили на два: $X_l =\{x \in X |[x^j < t]\}$ и $X_r = \{x \in X |[x^j > t]\}$(для среднеквадратичной ошибки)
- То как выдавать ответ: $a_m = \dfrac{1}{|X_m|}\sum\limits_{i \in X_m}y_i$,
классификации: $a_m = argmax_{y \in Y} \sum_{i \in X_m} [y_i = y]$
3. Критерий информативности (про оптимальное разбиение при построении бинарного дерева)
критерий ошибки: $Q(X_m, j, t) = \dfrac{|X_l|}{|X_m|}H(X_l) + \dfrac{|X_r|}{|X_m|}H(X_r)$
- регрессия : $H(x) = \dfrac{1}{|X|}\sum\limits_{i \in X}(y_i - \overline{y})$
- классификация:
	- критерий Джини:
$H(X) = \sum\limits_{k=1}^{K}(p_k)(1 - p_k)$, где $p_k = \dfrac{1}{X}\sum\limits_{i \in X}[y_i = k]$
	- Энтропийный критерий
$H(X) = - \sum\limits_{k = 1}^{K}p_k \ln{p_k}$

4. Критерий останова и стрижки деревьев
Используется для того, чтобы понять разбивать вершину дальше или сделать листовой. 
- $n$ - гиперпараметр, число объектов в вершине
- ограничивать глубину дерева
5. Работа с категориальными признаками 
- Подход 1: $N$-арные деревья
Тут мы $X_n$ разбиваем на $n$ частей
ну тут немного модернизируется функция ошибки.
$$Q(X_m, j) = \sum\limits_{i = 1}^n \dfrac{|X_i|}{|X_m|}H(X_i) \rightarrow \min\limits_j$$
- Подход2: бинарные деревья с разбиением множества значений 

# Урок 8: Случайные леса
Решающие деревья очень хорошо подходят для оюъединенения в композиции и построения одного неперобученного алгоритма на основе большого количества решающих деревьев. 

1. Композиции деревьев
Обучаем $b_1(x), ... b_N(x)$ а затем усредняем полученные ответы:
$a(x) = \dfrac{1}{N}\sum\limits_{n = 1}^{N} b_n(x)$ - регрессия
$a(x) = sign{\dfrac{1}{N}\sum\limits_{n=1}^N b_n(x)}$ - классификация
Очевидно на всей обучающий выборке обучать каждый алгоритм бесммысленно => используем **бутсрап** и **беггинг**

2. Смещение и разброс
**Опр:**(тут надо посмотреть рисунок и все станет понятным)
	1. Шум - компонента ошибки алгоритма которая проявляется даже на идеальной модели в этой задаче.
	2. Смещение - отклонение усредненного по различным обучающим выборкам, прогноза заданной модели от прогноза идеальной модели.
	3. Разброс - дисперсия ответов моделей, обученных по различным обучающим выборкам(*характеризует то, насколько сильно прогноз алгоритма зависит от конкретной обучающей выборки*)

$\dfrac{\text{разброс}}{\text{композции}} = 
\dfrac{1}{N} \left(\dfrac{\text{разброс одного }}{\text{базового алгоритма}} \right) +\left(\dfrac{\text{корелляция между}}{\text{базовыми алгоритмами}} \right)$

Для уменьшения корреляции используются **беггинг** и метод случайных подпространств.

3. Случайный лес (как один из лучших способов объединения деревьев в композиции)
Условие разбиения: $[x^j < t]$, параметры выбираются исходя из условий минимизации функции ошибки: $Q(X_m, j, t) \rightarrow \min\limits_{j,t}$.
(j - отвечает за номер признака,  t - за порог отсчения)

!!! Рандомизируем процесс выбирая $j$ из случайного подмножества признаков размера $q$ !!!
Рекомендации по выбору q:
- регрессия $q = \dfrac{d}{3}$
- классификация$q = \sqrt{d}$

**Алгоритм построения случайного леса:**
	1. С помощью бустрапа простроить N подвыборок
	2. Каждую подвыборку будем использовать как обучающую для построения соответствующего решающего дерева
	3. Построенные деревья объединяются в композиции:
- регрессия: $a(x) = \dfrac{1}{N}\sum\limits_{n = 1}^{N} b_n(x)$
- классификация $a(x) = sign \dfrac{1}{N} \sum\limits_{n = 1}^{N} b_n(x)$

*Особенности:*
- не переобучаются при рости числа базовых алгоритмов
- распаралеливание
- требуют очень большое число вычислительных ресурсов
- необходимость огромного количества дерьев при решении сложных задач (потому что каждое следующее дерево никак не зависит от предыдущих)

**out-of-bag подход** - оценка качества полученного леса без использования отложенной выборки или кросс-валидации. 

# Урок 9(Градиентый бустинг) 
Один из лучших способов направленного построения композиции. 
$$a_N(x) = \sum\limits_{n = 1}^N b_n(x)$$
Каждый следующий алгоритм корректирует ошибки предыдущего. 

**Функция потерь L(y,z)**:
- регрессия: $L(y, z) = (y - z)^2$
- классификация: $L(y,z) = \log{(1 + \exp{(-yz)})}$

## Построение базового алгоритма

Пусть обучили $N - 1$: $a_{N - 1} = \sum\limits_{n= 1}^{N - 1} b_n(x)$

$b_N(x)$ получим так, чтобы: $\sum_{i=1}^{l}L(y_i, a_{N-1}(x_i) +b(x_i) ) \rightarrow \min\limits_{b}$

Определим компоненты $s$, $b_N(x_i) = s_i$, так чтобы ошибка была минимальной: $F(s) = \sum_{i=1}^{l} L(y_i, a_{N-1}(x_i) + s_i) \rightarrow \min\limits_s$.

 Для этого воспользуемся вектором антиградента 
$$s = - \nabla F = \left(\begin{array}{c}{-L'_z(y_1, a_{N- 1}(x_1))} \\ {-L'_z(y_2, a_{N- 1}(x_2))} \\ {\vdots} \\ {-L'_z(y_l, a_{N - 1}(x_l))}\end{array}\right)$$

Итого: $b_N(x)$ - задача обучения на размеченных данных. Обучающая выборка $\{(x_i, s_i)\}_{i=1}^{l}$ и будем использовать квадратичную функцию ошибки, то есть:
$$b_N(x) = argmin_b \dfrac{1}{l}\sum_{i= 1}^{l}(b(x_i) - s_i)^2$$ (в этой строчке мы подбираем именно алгоритм)

## Проблемы градиентного бустинга

Переобучение с ростом числа деревьев, это связано с тем, что базовый алгоритм пытается приблизить вектор антиградиента на обучающей выборке.(но так как в бустинге используются очень маленькие деревья, то они не могут хорошо аппроксимировать вектор антиградиента) 

### Решение - сокращение размера шага
$$a_N(x) = a_{N - 1}(x) + \eta b_N(x), \eta \in(0,1]$$

- Чем меньше размер шага - тем больше нужно базовых алгоритмов чтобы достичь хорошего качества, и тем больше времени занимает потсроение
- Чем меньше шаг тем лучшего качества мы можем достичь

### Подбор гиперпараметров 
1. $N$- число итераций 
2. $\eta$ - размер шага
Используем кросс-валидацию 


## Градиентный бустинг для регрессии и классификации и для решающих деревьев

### Регрессия 
$MSE(a, X) = \dfrac{1}{l} \sum\limits_{i=1}^{l}(a(x_i) - y_i)^2$ - функционал ошибки
...(ну тут вроде понятно)

### Классификация

Функция потерь: $\sum\limits_{i = 1}^{n} \log{(1 + \exp{(-y_ia(x_i))})}$
- считаем вектор s

### Решающие деревья
ToDO: написать, пока не очень понял(((


## Урок 10

## Урок 11 (Байесовская классификация и регрессия)

## Урок 12 (Метрические алгоритмы и SVM)

## Урок 13 (Теорема Байеса в машинном обучении)

## Бонусный урок
()