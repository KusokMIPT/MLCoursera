{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task: https://www.coursera.org/learn/supervised-learning/programming/lWdVx/beghghingh-i-sluchainyi-lies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бэггинг и случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ans(file_name, ans):\n",
    "    with open(file_name, \"w\") as fout:\n",
    "        fout.write(str(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble, model_selection, metrics, tree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits_dataset = load_digits()\n",
    "X = digits_dataset.data\n",
    "y = digits_dataset.target\n",
    "print(digits_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из описания или с помощью 'digits_dataset.data.shape' понимаем что раотаем с 64 признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X.shape[1] # задали количество признаков\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 1\n",
    "\n",
    "Создадим класс DecisionTreeClassifier и измерим качество его работы с помощью cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ на пункт 1: 0.8241247672253259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cvs = cross_val_score(estimator=clf, X = X, y = y, cv=10)\n",
    "print('Ответ на пункт 1:', cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ans(\"answer1.txt\", cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим бэггинг над DecisionTreeClassifier. Зададим количество деревьев равным 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ на пункт 2: 0.9253786468032278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clf_bagging = BaggingClassifier(base_estimator= clf,\n",
    "                        n_estimators=100, random_state=0).fit(X, y)\n",
    "\n",
    "cvs = cross_val_score(estimator=clf_bagging, X = X, y = y, cv=10)\n",
    "\n",
    "print('Ответ на пункт 2:', cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Качество работы композиции решающих деревьев заметно выросло по сранвнеию с одним решающим деревом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ans(\"answer2.txt\", cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 3\n",
    "Добьёися того, чтобы каждый базовый алгоритм BaggingClassifier обучался не на всех d признаках, а на $\\sqrt{d}$. Для этого будем использовать параметр `max_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ на пункт 3: 0.9304283054003726\n"
     ]
    }
   ],
   "source": [
    "clf_bagging = BaggingClassifier(base_estimator= clf,\n",
    "                        n_estimators=100, random_state=0, max_features=int(np.sqrt(n_features))).fit(X, y)\n",
    "\n",
    "cvs = cross_val_score(estimator=clf_bagging, X = X, y = y, cv=10)\n",
    "print('Ответ на пункт 3:', cross_val_score(estimator=clf_bagging, X = X, y = y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Качество еще выросло."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ans(\"answer3.txt\", cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 4\n",
    "\n",
    "Попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Для этого нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier.\n",
    "(за это отвечает все тот же параметр `max_features` в классе `DecisionTreeClassifier`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ на пункт 4: 0.9510211049037863\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=0, max_features=int(np.sqrt(n_features)))\n",
    "clf_bagging = BaggingClassifier(base_estimator= clf,\n",
    "                        n_estimators=100, random_state=0).fit(X, y)\n",
    "\n",
    "cvs = cross_val_score(estimator=clf_bagging, X = X, y = y, cv=10)\n",
    "print('Ответ на пункт 4:', cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** качество выросло "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ans(\"answer4.txt\", cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 5\n",
    "1. Поймем что бэггинг на рандомизированных деревьях соответствует алгоритму Random Forest. Сравним их качество\n",
    "2. Посмотрим как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева (построим соответствующие графики)\n",
    "3. Выберем верные утверждения из следующего списка:\n",
    "\n",
    "    1) Случайный лес сильно переобучается с ростом количества деревьев\n",
    "    \n",
    "    2) При очень маленьком числе деревьев (5, 10, 15), случайный лес работает хуже, чем при большем числе деревьев\n",
    "    \n",
    "    3) С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
    "    \n",
    "    4) При большом количестве признаков (для данного датасета - 40, 50) качество классификации становится хуже, чем при малом количестве признаков (5, 10). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.\n",
    "    \n",
    "    5) При большом количестве признаков (40, 50, 60) качество классификации лучше, чем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков - тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно.\n",
    "    \n",
    "    6) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается.\n",
    "    \n",
    "    7) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг-друга)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 39s, sys: 2.23 s, total: 3min 41s\n",
      "Wall time: 3min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9482278088144008"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "bagging = BaggingClassifier(rf_classifier, n_estimators=100)\n",
    "\n",
    "cross_val_score(bagging, X, y, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# действительно ли тоже самое получилось?\n",
    "# обратить внимание на время обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm import tnrange\n",
    "from sklearn.model_selection import cross_val_score, validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим параметры для посотроения зависимости качества модели от количества дерьев,\n",
    "# количества признаков, огрнаичении на глубину дерева\n",
    "\n",
    "n_estimators_range = np.array([1] + [i for i in range(10,101, 10)])\n",
    "max_features_range = np.array([5,10,20,50, 64])\n",
    "max_depth_range = np.array([i for i in range(5,100, 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем пользоваться validation_curve для определния качества полченной модели\n",
    "\n",
    "(не learning_curve потому что подбираем гиперпараметры, а не *training_example*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# для n_estimators_range\n",
    "train_scores, test_scores = validation_curve(bagging, X, y, param_name=\"n_estimators\", \n",
    "                                             param_range=n_estimators_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.grid(True)\n",
    "pylab.title('Зависимость качество на тренировочной и тествой выборки взависимости от количества дереьев')\n",
    "pylab.plot(n_estimators_range, train_scores.mean(axis = 1), 'g-', marker='o', label='train')\n",
    "pylab.plot(n_estimators_range, test_scores.mean(axis = 1), 'r-', marker='o', label='test')\n",
    "pylab.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# для max_features_range\n",
    "train_scores_features, test_scores_features = validation_curve(bagging, X, y, param_name=\"max_features\", \n",
    "                                             param_range=max_features_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.grid(True)\n",
    "pylab.title('Зависимость качество на тренировочной и тествой выборки взависимости от числа признаков')\n",
    "pylab.plot(max_features_range, train_scores_features.mean(axis = 1), 'g-', marker='o', label='train')\n",
    "pylab.plot(max_features_range, test_scores_features.mean(axis = 1), 'r-', marker='o', label='test')\n",
    "pylab.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# для max_depth_range\n",
    "train_scores_depth, test_scores_depth = validation_curve(bagging, X, y, param_name=\"base_estimator__max_depth\", \n",
    "                                             param_range=max_features_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.grid(True)\n",
    "pylab.title('Зависимость качество на тренировочной и тествой выборки взависимости от числа макисмальной глубины дерева')\n",
    "pylab.plot(max_features_range, train_scores_depth.mean(axis = 1), 'g-', marker='o', label='train')\n",
    "pylab.plot(max_features_range, test_scores_depth.mean(axis = 1), 'r-', marker='o', label='test')\n",
    "pylab.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итого:** Верные утверждения из списка: \n",
    "2 3 4 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ans(\"answer5.txt\", '2 3 4 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "1. разобраться почему 4 правильный а не 5!\n",
    "2. Понять в чем разница юзать `validation_curve` или просто итерироваться по массиву с параметрами и на каждом этапе считать cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
